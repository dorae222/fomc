# FOMC

íŒ€ í† ì´ í”„ë¡œì íŠ¸ **FOMC** ì €ì¥ì†Œì…ë‹ˆë‹¤.  
ì›¹ ì„œë¹„ìŠ¤, ë°ì´í„° í¬ë¡¤ëŸ¬, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ì„ **ëª¨ë…¸ë ˆí¬(Monorepo)** êµ¬ì¡°ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”
- **Web (webapp/)**  
  ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ë°±ì—”ë“œ API  

- **Crawler (crawler/)**  
  ë°ì´í„° ìˆ˜ì§‘ê¸° (ì›¹ í¬ë¡¤ë§, API ìˆ˜ì§‘ ë“±)  

- **Model (model/)**  
  ë°ì´í„° ì „ì²˜ë¦¬, ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë° ì‹¤í—˜  

---

## Usage Process

This project follows a three-step process to analyze the market impact of FOMC communications.

### 1. Crawl FOMC Documents

First, you need to download the official FOMC documents (statements, transcripts, etc.) from the Federal Reserve website.

-   Run the crawler script to fetch documents for the desired period (e.g., 2023-2025):
    ```bash
    python crawler/2023_2025_crawl.py
    ```
-   The downloaded files will be saved in the `data/raw/2023_2025_crawled` directory.

### 2. Run Sentiment Analysis

Next, analyze the downloaded PDF documents to generate sentiment predictions.

-   **Install dependencies:** Make sure you have the necessary libraries installed.
    ```bash
    pip install torch transformers pdfplumber pandas spacy
    python -m spacy download en_core_web_sm
    ```
-   **Run predictions:** Use the `run_predictions.py` script, which reads the commands from `prediction_commands.txt` and executes them. This will save the sentiment data as `.csv` files in the `predicted/` directory.
    ```bash
    python model/run_predictions.py
    ```

### 3. Generate Market Impact Analysis

Finally, correlate the sentiment data with market data (e.g., QQQ) and generate plots.

-   **Install dependencies:**
    ```bash
    pip install yfinance pytz pandas matplotlib
    ```
-   **Run the analysis script:**
    ```bash
    python model/1hour_qqq.py
    ```
-   The output plots will be saved in the `results/plots/` directory.

---

## ğŸ“‚ ë””ë ‰í„°ë¦¬ êµ¬ì¡°
```

fomc/
â”œâ”€ webapp/          # í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ ì½”ë“œ
â”œâ”€ crawler/         # í¬ë¡¤ëŸ¬ ì½”ë“œ
â”œâ”€ model/           # ëª¨ë¸ í•™ìŠµ/í‰ê°€ ì½”ë“œ, ë…¸íŠ¸ë¶
â”œâ”€ data/            # ë¡œì»¬ ë°ì´í„° (gitignore ì²˜ë¦¬ë¨)
â”œâ”€ .github/         # GitHub Actions, ì´ìŠˆ/PR í…œí”Œë¦¿
â””â”€ README.md

````

---

## ğŸŒ± ë¸Œëœì¹˜ ì „ëµ
- **main**  
  ë°°í¬ ë° ì•ˆì •í™”ëœ ì½”ë“œë§Œ ìœ ì§€  

- **develop**  
  ê¸°ëŠ¥ í†µí•© ë° í…ŒìŠ¤íŠ¸  

- **web / crawler / model**  
  ì—­í• ë³„ ì¥ê¸° ë¸Œëœì¹˜  

- **ê¸°ëŠ¥ ë¸Œëœì¹˜ ê·œì¹™**  
  - `web/feature-login-ui`  
  - `crawler/feature-news-crawl`  
  - `model/experiment-baseline`  

---

## ğŸ”„ í˜‘ì—… ì›Œí¬í”Œë¡œìš°
1. ì—­í• ë³„ ë¸Œëœì¹˜ì—ì„œ ìµœì‹  ì½”ë“œ ê°€ì ¸ì˜¤ê¸°  
   ```bash
   git checkout web
   git pull
   git checkout -b web/feature-xxx
   ```

2. ê¸°ëŠ¥ ê°œë°œ â†’ ì»¤ë°‹ & í‘¸ì‹œ

   ```bash
   git add .
   git commit -m "web: add login UI"
   git push -u origin web/feature-xxx
   ```
3. GitHub Pull Request ìƒì„± â†’ ë¦¬ë·° & CI í†µê³¼
4. ì—­í•  ë¸Œëœì¹˜ â†’ develop â†’ main ìˆœì„œë¡œ ë³‘í•©

---

## âš™ï¸ ê°œë°œ í™˜ê²½

### ê³µí†µ

* **Git** (Windows: Git for Windows)
* **VS Code** (ê¶Œì¥)
* **í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬**: ê° í´ë”ì˜ `.env` íŒŒì¼ ì‚¬ìš©

  > `.env`ëŠ” `.gitignore`ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ GitHubì— ì˜¬ë¼ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

### ğŸ”µ Web (webapp/)

* **í•„ìˆ˜**: Node.js 20 LTS, npm
* **ì´ˆê¸° ì„¤ì •**

  ```bash
  cd webapp
  npm install   # ì˜ì¡´ì„± ì„¤ì¹˜
  ```
* **ê°œë°œ ì„œë²„ ì‹¤í–‰**

  ```bash
  npm run dev
  ```
* **ë¹Œë“œ**

  ```bash
  npm run build
  ```
* **í…ŒìŠ¤íŠ¸**

  ```bash
  npm test
  ```

---

### ğŸŸ¢ Crawler (crawler/)

* **í•„ìˆ˜**: Python 3.11
* **ê°€ìƒí™˜ê²½ ìƒì„± (Windows PowerShell)**

  ```powershell
  cd crawler
  python -m venv .venv
  .\.venv\Scripts\Activate.ps1
  pip install -r requirements.txt
  ```
* **ì‹¤í–‰ ì˜ˆì‹œ**

  ```powershell
  python src/news_crawler.py --date 2025-01-01
  ```

---

### ğŸŸ£ Model (model/)

* **í•„ìˆ˜**: Python 3.11, Jupyter Notebook (ë˜ëŠ” VS Code Jupyter)
* **í™˜ê²½ ì„¤ì •**

  ```powershell
  cd model
  python -m venv .venv
  .\.venv\Scripts\Activate.ps1
  pip install -r requirements.txt
  ```
* **ë…¸íŠ¸ë¶ ì‹¤í–‰**

  ```powershell
  jupyter notebook
  ```
* **í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (pytest ì‚¬ìš© ì‹œ)**

  ```powershell
  pytest src/tests/
  ```

---

## ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ (ë¹ ë¥¸ ì‹œì‘)

```powershell
# 1. ë ˆí¬ í´ë¡ 
git clone git@github.com:<org-or-user>/fomc.git
cd fomc

# 2. web ì„œë²„ ì‹¤í–‰
cd webapp
npm install
npm run dev

# 3. crawler ì‹¤í–‰
cd ../crawler
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python src/news_crawler.py

# 4. model í•™ìŠµ ì‹¤í–‰
cd ../model
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
jupyter notebook
```

---

## ğŸ› ï¸ ê¸°ì—¬ ê°€ì´ë“œ

* ëª¨ë“  PRì€ ìµœì†Œ 1ëª… ë¦¬ë·° í›„ ë¨¸ì§€
* ì»¤ë°‹ ë©”ì‹œì§€ ê·œì¹™:

  * `web: ...`, `crawler: ...`, `model: ...`
* CI í†µê³¼ í•„ìˆ˜ (`.github/workflows/ci.yml`)# FOMC_NLP_v1.0
# FOMC_NLP_v1.0
